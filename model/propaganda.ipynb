{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1fb9fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/solopov97/Downloads/prorus_text.txt','r') as ru:\n",
    "    ru=list(ru)\n",
    "    ru=[e.replace('\\n','') for e in ru]\n",
    "with open('/Users/solopov97/Downloads/prouk_text.txt','r') as uk:\n",
    "    uk=list(uk)\n",
    "    uk=[e.replace('\\n','') for e in uk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e5125798",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/solopov97/Downloads/telegram_fake.txt','r') as fru:\n",
    "    fru=list(fru)\n",
    "    fru=[e.replace('\\n','') for e in fru]\n",
    "with open('/Users/solopov97/Downloads/telegram_real.txt','r') as fuk:\n",
    "    fuk=list(fuk)\n",
    "    fuk=[e.replace('\\n','') for e in fuk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c1b113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/solopov97/Downloads/french_fake.txt','r') as fru:\n",
    "    fru=list(fru)\n",
    "    fru=[e.replace('\\n','') for e in fru]\n",
    "with open('/Users/solopov97/Downloads/french_real.txt','r') as fuk:\n",
    "    fuk=list(fuk)\n",
    "    fuk=[e.replace('\\n','') for e in fuk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd0f308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/solopov97/Downloads/prorus_text_nofrench.txt','r') as ru:\n",
    "    ru=list(ru)\n",
    "    ru=[e.replace('\\n','') for e in ru]\n",
    "with open('/Users/solopov97/Downloads/prouk_text_nofrench.txt','r') as uk:\n",
    "    uk=list(uk)\n",
    "    uk=[e.replace('\\n','') for e in uk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a1cb53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_fuk=[1 for e in fuk]\n",
    "labels_fru=[0 for e in fru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b2f770fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7263, 61595)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fuk), len(fru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cb424878",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_uk=[1 for e in uk]\n",
    "labels_ru=[0 for e in ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "345def5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = {'X':fuk,'Y':labels_fuk}\n",
    "df_fuk = pd.DataFrame(u)\n",
    "r = {'X':fru,'Y':labels_fru}\n",
    "df_fru = pd.DataFrame(r)\n",
    "dff=pd.concat([df_fuk,df_fru], axis=0)\n",
    "Xf=dff['X'].values.tolist()\n",
    "Yf=dff['Y'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a646933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = {'X':uk,'Y':labels_uk}\n",
    "df_uk = pd.DataFrame(u)\n",
    "r = {'X':ru,'Y':labels_ru}\n",
    "df_ru = pd.DataFrame(r)\n",
    "df=pd.concat([df_uk,df_ru], axis=0)\n",
    "Xf=df['X'].values.tolist()\n",
    "Yf=df['Y'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7d4dad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall=pd.concat([df_uk,df_ru,df_fuk,df_fru], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "97d8ce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.10, random_state=80)\n",
    "X=test_df['X'].values.tolist()\n",
    "Y=test_df['Y'].values.tolist()\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "32855979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f9034ce24c4c58a15c6b17ced48762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1827 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be098bd27a6412cb4ac56c2390f4cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ClassificationModel(\n",
    "    \"bert\", \"/Users/solopov97/Desktop/GERMANY/DR.SOLOPOVA/features/out_propaganda/1/outputs/best_model\",use_cuda=False)\n",
    "predictions1, raw_outputs1 = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ed43ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fe4e7da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8180761020249265"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "Y=test_df['Y'].values.tolist()\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "k=sklearn.metrics.cohen_kappa_score(predictions, Y)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "917321ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864886932294056\n",
      "0.9326765188834154\n"
     ]
    }
   ],
   "source": [
    "k=sklearn.metrics.cohen_kappa_score(predictions1,Y)\n",
    "print(k)\n",
    "from sklearn.metrics import f1_score\n",
    "f1=f1_score(Y, predictions1 ,\n",
    "            average='micro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8e9ad272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 111 779 925\n"
     ]
    }
   ],
   "source": [
    "fp=0\n",
    "fn=0\n",
    "tp=0\n",
    "tn=0\n",
    "for tr,pr in zip(Y, predictions1):\n",
    "    if tr==pr and tr==1:\n",
    "        tp+=1\n",
    "    elif tr==pr and tr==0:\n",
    "        tn+=1\n",
    "    elif tr!=pr and tr==1:\n",
    "        fn+=1\n",
    "    elif tr!=pr and tr==0:\n",
    "        fp+=1   \n",
    "print(fp,fn,tp,tn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4801a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "seeds=[24,42,10,80,63]\n",
    "seeds=[80]\n",
    "all_outputs=[]\n",
    "all_results=[]\n",
    "true=[]\n",
    "pred=[]\n",
    "def f1_multiclass(labels, preds):\n",
    "    true.append(labels)\n",
    "    pred.append(preds)\n",
    "    return f1_score(labels, preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7dd407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4c42c3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/solopov97/opt/anaconda3/lib/python3.9/site-packages/simpletransformers/classification/classification_model.py:585: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b9b1b73b1d497f84d1beb40a4e57ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29506 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/solopov97/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e04005c46044afbc3b5a336ac1f43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7872c63195194abcb1d784429c938def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/3689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6816563cb90428487b3d211c77248fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/3689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae3aef6bbf44b5484763d04d906498c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/3689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab54726227e4b30909d291873280a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/3689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/solopov97/opt/anaconda3/lib/python3.9/site-packages/simpletransformers/classification/classification_model.py:1426: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253132d715594a55b2a699fa773e9313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bac61181db4f0a94c4878f70d2fd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcc': 0.8181791737286435, 'tp': 1440, 'tn': 1541, 'fp': 136, 'fn': 162, 'auroc': 0.9649387281997682, 'auprc': 0.9616197730852462, 'f1': 0.9091186337297956, 'acc': 0.9091186337297956, 'eval_loss': 0.40182820134796204}\n"
     ]
    }
   ],
   "source": [
    "for e in seeds:\n",
    "    train_args ={\"reprocess_input_data\": True,\n",
    "              \"fp16\":False,\n",
    "              \"num_train_epochs\": 4,\n",
    "            \"save_model_every_epoch\": True,\n",
    "            \"output_dir\":'/Users/solopov97/Desktop/GERMANY/DR.SOLOPOVA/features/out_propaganda/'+str(counter)+'/outputs'}\n",
    "    train_df, test_df = train_test_split(dfall, test_size=0.10, random_state=e)\n",
    "    model = ClassificationModel(\"bert\",\"bert-base-multilingual-cased\",num_labels=2,\n",
    "                            args=train_args,use_cuda=False)\n",
    "    print('model ready')\n",
    "    model.train_model(train_df,overwrite_output_dir=True)\n",
    "    print('train ready')\n",
    "    result, model_outputs, wrong_predictions = model.eval_model(test_df, f1=f1_multiclass, acc=accuracy_score)\n",
    "    all_results.append(result)\n",
    "    all_outputs.append(model_outputs)\n",
    "    print(result)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d4bac1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fb4427961a4eb8938313e8cd5456ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482c2831da4f44ffb5618b48d1dc3fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, raw_outputs = model.predict(test_df['X'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e5e9c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90ee3bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9117082533589251\n",
      "0.9232245681381958\n",
      "0.9238643634037108\n",
      "0.9289827255278311\n",
      "0.9174664107485605\n"
     ]
    }
   ],
   "source": [
    "f1s=[]\n",
    "for i in all_results:\n",
    "    print(i['f1'])\n",
    "    f1s.append(i['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbfcac91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210492642354445"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f1s)/len(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335c572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
